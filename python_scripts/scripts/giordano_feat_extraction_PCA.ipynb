{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9dfcf1b2-dba2-4b0b-9891-4233268e659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "import joblib\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147b961b-bf91-4e48-a8b4-fc51563ee0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    print(datetime.now().strftime(\"%H:%M:%S\"), f\":builder: Worker {worker_id} started\")\n",
    "\n",
    "# Helper to get candidate layers for PCA\n",
    "def get_relevant_output_layers(model, model_name):\n",
    "    \"\"\"\n",
    "    Returns a list of brain-relevant layers to extract from a given model,\n",
    "    approximately mapping to V1, V4, and IT.\n",
    "    \"\"\"\n",
    "    if model_name == 'resnet18':\n",
    "        return [\n",
    "            'conv1',                         # V1\n",
    "            'layer1.0.relu_1',               # V2\n",
    "            'layer1.1.relu_1',               # V2/V4\n",
    "            'layer2.0.relu_1',               # V4\n",
    "            'layer2.1.relu_1',               # V4\n",
    "            'layer3.0.relu_1',               # V4/IT\n",
    "            'layer3.1.relu_1',               # IT\n",
    "            'layer4.0.relu_1',               # IT\n",
    "            'layer4.1.relu_1',               # IT\n",
    "            'avgpool'                        # pooled features (IT-like)\n",
    "        ]\n",
    "    if model_name == 'resnet50':\n",
    "        return [\n",
    "            'conv1',                         # V1\n",
    "            'layer1.0.relu_2',\n",
    "            'layer1.1.relu_2',               # V2\n",
    "            'layer1.2.relu_2',               # V2\n",
    "            'layer2.0.relu_2',\n",
    "            'layer2.1.relu_2',               # V4\n",
    "            'layer2.2.relu_2',               # V4\n",
    "            'layer2.3.relu_2',               # V4\n",
    "            'layer3.0.relu_2',\n",
    "            'layer3.1.relu_2',               # V4/IT\n",
    "            'layer3.2.relu_2',               # V4/IT\n",
    "            'layer3.3.relu_2',               # IT-like\n",
    "            'layer3.4.relu_2',\n",
    "            'layer3.5.relu_2',               # IT-like\n",
    "            'layer4.0.relu_2',\n",
    "            'layer4.1.relu_2',               # IT-like\n",
    "            'layer4.2.relu_2',\n",
    "            'avgpool'\n",
    "        ]\n",
    "    if model_name == 'vgg16':\n",
    "        return [\n",
    "            'features.0',       # conv1_1 (V1)\n",
    "            'features.2',       # conv1_2\n",
    "            'features.5',       # conv2_2\n",
    "            'features.10',      # conv3_3\n",
    "            'features.12',      # conv4_1\n",
    "            'features.16',      # conv4_3\n",
    "            'features.19',      # conv5_1\n",
    "            'features.23',      # conv5_3\n",
    "            'features.30',      # final conv\n",
    "            'classifier.0'      # first FC layer\n",
    "        ]\n",
    "    if model_name == 'alexnet':\n",
    "        return [\n",
    "            'features.0',       # conv1\n",
    "            'features.4',       # conv2\n",
    "            'features.7',       # conv3\n",
    "            'features.9',       # conv4\n",
    "            'features.11',      # conv5\n",
    "            'classifier.2',     # fc6\n",
    "            'classifier.5'      # fc7\n",
    "        ]\n",
    "    if model_name == 'vit_b_16':\n",
    "        return [\n",
    "            'conv_proj',                                      # patch embedding (V1-like)\n",
    "            'encoder.layers.encoder_layer_0.add_1',           # early transformer block ← V1\n",
    "            'encoder.layers.encoder_layer_2.add_1',           # mid/early block\n",
    "            'encoder.layers.encoder_layer_4.add_1',           # mid\n",
    "            'encoder.layers.encoder_layer_6.add_1',           # V4-like\n",
    "            'encoder.layers.encoder_layer_8.add_1',           # higher block\n",
    "            'encoder.layers.encoder_layer_10.add_1',          # deep\n",
    "            'encoder.layers.encoder_layer_11.add_1',          # very deep ← IT\n",
    "            'encoder.ln',                                     # final transformer output\n",
    "            'heads.head'                                      # classification head ← IT\n",
    "        ]\n",
    "    raise ValueError(f\"Model {model_name} not supported in `get_relevant_output_layers()`.\")\n",
    "    # else:\n",
    "    #     all_nodes, _ = get_graph_node_names(model)\n",
    "    #     # Keep layers that are ReLU outputs or last ReLU in a residual block\n",
    "    #     return [name for name in all_nodes if name.endswith('relu_1') or name.endswith('relu')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21b51d90-fcd2-45b6-9a21-d700b79e0855",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca_pipeline(model_name='resnet18', layers_to_extract=None, n_components=1000,\n",
    "                     batch_size=512, multiple_passes=False, num_workers=2):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    # === Paths ===\n",
    "    imagenet_path = r\"path/to/imagenet\" #FIXME add mine\n",
    "    imagenet_val_path = os.path.join(imagenet_path, \"val\")\n",
    "    neural_data_path = r\"path/to/neural_fitting_tools\" #FIXME add mine\n",
    "    # === Transforms & Dataloader ===\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    # === Load model ===\n",
    "    model_cls = getattr(models, model_name)\n",
    "    model = model_cls(pretrained=True).to(device).eval()\n",
    "    if layers_to_extract is None:\n",
    "        layers_to_extract = get_relevant_output_layers(model, model_name)\n",
    "    # Filter out already done layers\n",
    "    remaining_layers = []\n",
    "    for layer in layers_to_extract:\n",
    "        save_name = f\"imagenet_val_{model_name}_{layer}_pca_model.pkl\"\n",
    "        path = os.path.join(neural_data_path, save_name)\n",
    "        if os.path.exists(path):\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), f\":white_tick: PCA model already exists for {layer} → {path}\")\n",
    "        else:\n",
    "            remaining_layers.append(layer)\n",
    "    if len(remaining_layers) == 0:\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \":white_tick: All PCA models already exist. Nothing to do.\")\n",
    "        return\n",
    "    print(f\"\\n:satellite_antenna: Model: {model_name} | Layers to process: {len(remaining_layers)}\")\n",
    "    # === Option 1: All layers in one pass ===\n",
    "    if not multiple_passes:\n",
    "        feature_extractor = create_feature_extractor(model, return_nodes=remaining_layers).to(device)\n",
    "        # Initialize PCA for each layer separately\n",
    "        pcas = {}\n",
    "        for layer in remaining_layers:\n",
    "            with torch.no_grad():\n",
    "                tmp_shape = feature_extractor(torch.randn(1, 3, 224, 224).to(device))[layer].shape[1:]\n",
    "            n_features = np.prod(tmp_shape)  # [C, H, W] -> C*H*W\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), f\"Layer: {layer} | Number of features: {n_features}\")\n",
    "            n_components_layer = min(n_features, n_components)  # Limit to number of features\n",
    "            pcas[layer] = IncrementalPCA(n_components=n_components_layer)\n",
    "        loader = DataLoader(\n",
    "            datasets.ImageFolder(imagenet_val_path, transform=transform),\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=worker_init_fn,\n",
    "            timeout=100\n",
    "        )\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \":hourglass_flowing_sand: Single-pass PCA fitting across all layers...\")\n",
    "        for inputs, _ in tqdm(loader, desc=\"Fitting PCA\"):\n",
    "            with torch.no_grad():\n",
    "                inputs = inputs.to(device)\n",
    "                outputs = feature_extractor(inputs)\n",
    "            for layer_name, tensor in outputs.items():\n",
    "                feats = tensor.view(tensor.size(0), -1).cpu().numpy()\n",
    "                pcas[layer_name].partial_fit(feats)\n",
    "        for layer_name, pca in pcas.items():\n",
    "            save_name = f\"imagenet_val_{model_name}_{layer_name}_pca_model.pkl\"\n",
    "            path = os.path.join(neural_data_path, save_name)\n",
    "            joblib.dump(pca, path)\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), f\":white_tick: Saved PCA for {layer_name} → {path}\")\n",
    "    # === Option 2: Loop over layers separately ===\n",
    "    else:\n",
    "        print(datetime.now().strftime(\"%H:%M:%S\"), \":cyclone: Using multiple passes (1 per layer)...\")\n",
    "        for layer_name in remaining_layers:\n",
    "            print(f\":hourglass_flowing_sand: Fitting PCA for layer: {layer_name}\")\n",
    "            feature_extractor = create_feature_extractor(model, return_nodes=[layer_name]).to(device)\n",
    "            with torch.no_grad():\n",
    "                tmp_shape = feature_extractor(torch.randn(1, 3, 224, 224).to(device))[layer_name].shape[1:]\n",
    "            n_features = np.prod(tmp_shape)  # [C, H, W] -> C*H*W\n",
    "            n_components_layer = min(n_features, n_components)  # Limit to number of features\n",
    "            pca = IncrementalPCA(n_components=n_components_layer)\n",
    "            loader = DataLoader(\n",
    "                datasets.ImageFolder(imagenet_val_path, transform=transform),\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True,\n",
    "                num_workers=num_workers,\n",
    "                pin_memory=True,\n",
    "                worker_init_fn=worker_init_fn,\n",
    "                timeout=100\n",
    "            )\n",
    "            for inputs, _ in tqdm(loader, desc=f\"PCA: {layer_name}\"):\n",
    "                with torch.no_grad():\n",
    "                    inputs = inputs.to(device)\n",
    "                    feats = feature_extractor(inputs)[layer_name]\n",
    "                    feats = feats.view(feats.size(0), -1).cpu().numpy()\n",
    "                    pca.partial_fit(feats)\n",
    "            save_name = f\"imagenet_val_{model_name}_{layer_name}_pca_model.pkl\"\n",
    "            path = os.path.join(neural_data_path, save_name)\n",
    "            joblib.dump(pca, path)\n",
    "            print(datetime.now().strftime(\"%H:%M:%S\"), f\":white_tick: Saved PCA for {layer_name} → {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eed56d-3938-47c7-ab1a-7ed1a510556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser(description=\"Run Incremental PCA for CNN layers\")\n",
    "    parser.add_argument('--model_name', type=str, default='resnet18')\n",
    "    parser.add_argument('--batch_size', type=int, default=512)\n",
    "    parser.add_argument('--n_components', type=int, default=1000)\n",
    "    parser.add_argument('--num_workers', type=int, default=2)\n",
    "    parser.add_argument('--multiple_passes', action='store_true')  # Flag → default False\n",
    "    args = parser.parse_args()\n",
    "    run_pca_pipeline(\n",
    "        model_name=args.model_name,\n",
    "        n_components=args.n_components,\n",
    "        batch_size=args.batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        multiple_passes=args.multiple_passes\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponce_env",
   "language": "python",
   "name": "ponce_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
