{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceab3369-b28c-4ee6-b8e5-fee7c1f346bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3339035683.py, line 3)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mfrom ../../src/alignment.utils import read_yaml\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "from torchvision.models.feature_extraction import create_feature_extractor, get_graph_node_names\n",
    "import os, yaml, sys\n",
    "ENV = os.getenv(\"MY_ENV\", \"dev\")\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "paths = config[ENV][\"paths\"]\n",
    "sys.path.append(paths[\"src_path\"])\n",
    "from dim_redu_anns.utils import get_relevant_output_layers, get_layer_out_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692af23e-b5e6-4f31-995f-d33fb9fca2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['x', 'features.0', 'features.1.block.0', 'features.1.block.1', 'features.1.add', 'features.2.block.0', 'features.2.block.1', 'features.2.block.2', 'features.3.block.0', 'features.3.block.1', 'features.3.block.2', 'features.3.add', 'features.4.block.0', 'features.4.block.1', 'features.4.block.2', 'features.4.block.3', 'features.5.block.0', 'features.5.block.1', 'features.5.block.2', 'features.5.block.3', 'features.5.add', 'features.6.block.0', 'features.6.block.1', 'features.6.block.2', 'features.6.block.3', 'features.6.add', 'features.7.block.0', 'features.7.block.1', 'features.7.block.2', 'features.8.block.0', 'features.8.block.1', 'features.8.block.2', 'features.8.add', 'features.9.block.0', 'features.9.block.1', 'features.9.block.2', 'features.9.add', 'features.10.block.0', 'features.10.block.1', 'features.10.block.2', 'features.10.add', 'features.11.block.0', 'features.11.block.1', 'features.11.block.2', 'features.11.block.3', 'features.12.block.0', 'features.12.block.1', 'features.12.block.2', 'features.12.block.3', 'features.12.add', 'features.13.block.0', 'features.13.block.1', 'features.13.block.2', 'features.13.block.3', 'features.14.block.0', 'features.14.block.1', 'features.14.block.2', 'features.14.block.3', 'features.14.add', 'features.15.block.0', 'features.15.block.1', 'features.15.block.2', 'features.15.block.3', 'features.15.add', 'features.16', 'avgpool', 'flatten', 'classifier.0', 'classifier.1', 'classifier.2', 'classifier.3']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = mobilenet_v3_large(pretrained=True)\n",
    "# Get available nodes you can extract features from\n",
    "train_nodes, eval_nodes = get_graph_node_names(model)\n",
    "print(eval_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e49766a-53a7-4b3b-8f39-ff3ede8bc806",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1)\n",
    "model2 = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2569d706-f847-48c7-ad84-b443952f6f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([120, 28, 28])\n",
      "torch.Size([960, 7, 7])\n",
      "torch.Size([120, 28, 28])\n",
      "torch.Size([960, 7, 7])\n",
      "torch.Size([120, 28, 28])\n",
      "torch.Size([960, 7, 7])\n",
      "torch.Size([40, 28, 28])\n",
      "torch.Size([160, 7, 7])\n",
      "torch.Size([1280])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "layers = get_relevant_output_layers(\"mobilenet_v3_large\")\n",
    "for layer_idx in range(len(layers)):\n",
    "    feature_extractor = create_feature_extractor(\n",
    "        model1, return_nodes=[layers[layer_idx]]\n",
    "    )\n",
    "    print(get_layer_out_shape(feature_extractor, layers[layer_idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponce_env",
   "language": "python",
   "name": "ponce_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
