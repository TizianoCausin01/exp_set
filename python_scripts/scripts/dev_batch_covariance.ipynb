{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38ea1a08-a064-4846-be36-4e823c02a78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, yaml, sys\n",
    "ENV = os.getenv(\"MY_ENV\", \"dev\")\n",
    "with open(\"../../config.yaml\", \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "paths = config[ENV][\"paths\"]\n",
    "sys.path.append(paths[\"src_path\"])\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "d66f3838-2c60-4e5b-af2e-fb7e59694e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_gram(K):\n",
    "    \"\"\"Center a Gram matrix.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    return H @ K @ H\n",
    "\n",
    "def hsic(K, L):\n",
    "    \"\"\"Hilbert-Schmidt Independence Criterion (biased).\"\"\"\n",
    "    n = K.shape[0]\n",
    "    Kc, Lc = center_gram(K), center_gram(L)\n",
    "    trace_test = np.trace(Kc @ Lc) / (n - 1) ** 2\n",
    "    dot_test = np.dot(Kc.flatten(), Lc.flatten())\n",
    "    #assert(np.allclose(trace_test, dot_test))\n",
    "    return np.trace(Kc @ Lc) / (n - 1) ** 2\n",
    "    #return dot_test\n",
    "    \n",
    "def cka(X, Y, kernel=\"linear\", **kwargs):\n",
    "    \"\"\"\n",
    "    Compute CKA between two representations X, Y.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : ndarray of shape (n_samples, d1)\n",
    "    Y : ndarray of shape (n_samples, d2)\n",
    "    kernel : str or callable\n",
    "        - \"linear\": use linear kernel\n",
    "        - any kernel name supported by sklearn (e.g. \"rbf\", \"poly\")\n",
    "    kwargs : extra arguments for sklearn pairwise_kernels\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cka_value : float\n",
    "        Centered Kernel Alignment value in [0, 1].\n",
    "    \"\"\"\n",
    "    # Build Gram matrices\n",
    "    if kernel == \"linear\":\n",
    "        K = X @ X.T\n",
    "        L = Y @ Y.T\n",
    "    else:\n",
    "        K = pairwise_kernels(X, metric=kernel, **kwargs)\n",
    "        L = pairwise_kernels(Y, metric=kernel, **kwargs)\n",
    "    \n",
    "    # Compute normalized HSIC\n",
    "    hsic_xy = hsic(K, L)\n",
    "    hsic_xx = hsic(K, K)\n",
    "    hsic_yy = hsic(L, L)\n",
    "    \n",
    "    return hsic_xy / np.sqrt(hsic_xx * hsic_yy + 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "715731fe-d9cf-49b6-8b9b-900c1a308c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear CKA: 0.8965122658886783\n",
      "RBF CKA: 0.9999955030298343\n"
     ]
    }
   ],
   "source": [
    "# Random activations from two layers\n",
    "X = np.random.randn(3000, 1000)  # 100 samples, 128 neurons\n",
    "Y = 5*X +2*np.random.randn(3000, 1000)  # 100 samples, 256 neurons\n",
    "\n",
    "# Linear CKA\n",
    "print(\"Linear CKA:\", cka(X, Y, kernel=\"linear\"))\n",
    "\n",
    "# RBF CKA\n",
    "print(\"RBF CKA:\", cka(X, Y, kernel=\"rbf\", gamma=1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "5c16203c-eb49-4164-bf0f-bd90664c3bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check if it's correct or not ... is it correct to sum stuff? or shall I first compute everything and then do the hsic like in the paper\n",
    "# TODO check also how the trend goes for CKA with respect to the others\n",
    "def center_gram_torch(K):\n",
    "    \"\"\"Center Gram matrix (Torch version).\"\"\"\n",
    "    n = K.size(0)\n",
    "    H = torch.eye(n, device=K.device) - torch.ones((n, n), device=K.device) / n\n",
    "    return H @ K @ H\n",
    "\n",
    "def hsic_torch(K, L):\n",
    "    \"\"\"HSIC estimate (biased).\"\"\"\n",
    "    n = K.size(0)\n",
    "    Kc, Lc = center_gram_torch(K), center_gram_torch(L)\n",
    "    return torch.trace(Kc @ Lc) / ((n - 1) ** 2)\n",
    "\n",
    "def cka_minibatch(X, Y, kernel=\"linear\", **kwargs):\n",
    "    \"\"\"\n",
    "    Minibatch version of CKA in PyTorch.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : tensor, shape (batch_size, d1)\n",
    "    Y : tensor, shape (batch_size, d2)\n",
    "    kernel : str\n",
    "        \"linear\" or \"rbf\"\n",
    "    kwargs : parameters for RBF kernel (e.g., gamma)\n",
    "    \"\"\"\n",
    "    if kernel == \"linear\":\n",
    "        K = X @ X.T\n",
    "        L = Y @ Y.T\n",
    "    else:\n",
    "        K = pairwise_kernels(X_batch, metric=kernel, **kwargs)\n",
    "        L = pairwise_kernels(Y_batch, metric=kernel, **kwargs)\n",
    "    \n",
    "    hsic_xy = hsic_unbiased(K, L)\n",
    "    hsic_xx = hsic_unbiased(K, K)\n",
    "    hsic_yy = hsic_unbiased(L, L)\n",
    "    #return hsic_xy / np.sqrt(hsic_xx * hsic_yy + 1e-12)\n",
    "    return hsic_xy, hsic_xx, hsic_yy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "0bc00a64-fc9c-4f34-b031-9ee438c7d47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsic_unbiased(K, L):\n",
    "    \"\"\"Unbiased HSIC estimator (Song et al. 2007) in NumPy.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    if n < 4:\n",
    "        raise ValueError(\"Need at least 4 samples for unbiased HSIC\")\n",
    "\n",
    "    # make a copy and zero diagonals\n",
    "    K = K.copy()\n",
    "    L = L.copy()\n",
    "    np.fill_diagonal(K, 0)\n",
    "    np.fill_diagonal(L, 0)\n",
    "\n",
    "    ones = np.ones((n, 1))\n",
    "\n",
    "    term1 = np.trace(K @ L).item()  \n",
    "    term2 = ((ones.T @ K @ ones) * (ones.T @ L @ ones) / ((n - 1) * (n - 2))).item()\n",
    "    term3 = (2 * (ones.T @ (K @ L) @ ones) / (n - 2)).item()\n",
    "    return float((term1 + term2 - term3) / (n * (n - 3)))\n",
    "\n",
    "def cka_batch_collection(xy, xx, yy):\n",
    "    return xy / (np.sqrt(xx) *np.sqrt(yy)+ 1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7bc42c44-94a0-4b5d-85a0-853f4c1517fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated minibatch CKA: 0.8620060373731601\n"
     ]
    }
   ],
   "source": [
    "cka_scores = []\n",
    "prev_idx = 0\n",
    "xy, xx, yy = 0, 0, 0\n",
    "n_pts = X.shape[0]\n",
    "batch_size = n_pts\n",
    "batch_num = n_pts // batch_size\n",
    "idx = np.random.choice(np.arange(n_pts), size=n_pts, replace=False)\n",
    "prev_idx = 0\n",
    "counter = 0\n",
    "for i in range(batch_size, n_pts+batch_size, batch_size):  # iterate over minibatches\n",
    "    i = min(i, n_pts)\n",
    "    #X_batch, Y_batch = X_batch.cuda(), Y_batch.cuda()\n",
    "    #idx = np.random.choice(np.arange(n_pts), size=batch_size, replace=False)\n",
    "    #X_batch, Y_batch = X[idx, :], Y[idx, :]\n",
    "    #print(\"batch start\", prev_idx, \"batch end\", i-1)\n",
    "    counter +=1\n",
    "    #print(counter)\n",
    "    rand_idx = idx[prev_idx:i]\n",
    "    X_batch, Y_batch = X[rand_idx, :], Y[rand_idx, :]\n",
    "    prev_idx = i\n",
    "    xy_n, xx_n, yy_n = cka_minibatch(X_batch, Y_batch, kernel=\"linear\")\n",
    "    xy += xy_n\n",
    "    xx += xx_n\n",
    "    yy += yy_n\n",
    "#cka_value = np.mean(np.stack(cka_scores))\n",
    "print(\"Estimated minibatch CKA:\", cka_batch_collection(xy, xx, yy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cb2d019c-ab76-4b14-870d-878f447f5e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "for i in range(batch_size, n_pts, batch_size):  # iterate over minibatches\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7bd26eb5-c61a-4482-9234-fc858ea2c929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.00870454970006897\n"
     ]
    }
   ],
   "source": [
    "n_pts = X.shape[0]\n",
    "batch_size = 10\n",
    "num_batches = n_pts // batch_size\n",
    "\n",
    "xy_sum, xx_sum, yy_sum = 0.0, 0.0, 0.0\n",
    "\n",
    "for i in range(num_batches):\n",
    "    start = i * batch_size\n",
    "    end = (i + 1) * batch_size\n",
    "    X_batch, Y_batch = X[start:end, :], Y[start:end, :]\n",
    "    xy_n, xx_n, yy_n = cka_minibatch(X_batch, Y_batch, kernel=\"linear\")\n",
    "    xy_sum += xy_n\n",
    "    xx_sum += xx_n\n",
    "    yy_sum += yy_n\n",
    "\n",
    "xy_avg = xy_sum / num_batches\n",
    "xx_avg = xx_sum / num_batches\n",
    "yy_avg = yy_sum / num_batches\n",
    "\n",
    "cka_est = xy_avg / np.sqrt(xx_avg * yy_avg)\n",
    "print(cka_est)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a358e32-66f7-4787-a4d9-f603815afdd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n",
      "10 20\n",
      "20 30\n",
      "30 40\n",
      "40 50\n",
      "50 60\n",
      "60 70\n",
      "70 80\n",
      "80 90\n"
     ]
    }
   ],
   "source": [
    "prev_idx = 0\n",
    "for i in range(10, 100, 10):  # iterate over minibatches\n",
    "    #X_batch, Y_batch = X_batch.cuda(), Y_batch.cuda()\n",
    "    print(prev_idx, i)\n",
    "    prev_idx = i\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cf2b54f-c97a-45ae-b513-0d7e5535ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "8\n",
      "15\n",
      "22\n",
      "29\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 40, 7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43e424de-edb3-4d53-b7f4-f148a5120a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Comparison with BIASED HSIC ===\n",
      "Exact CKA (biased HSIC): 0.151661\n",
      "Minibatch CKA (biased HSIC): 0.636501\n",
      "Difference: 0.484841\n",
      "\n",
      "=== Comparison with UNBIASED HSIC ===\n",
      "Exact CKA (unbiased HSIC): -0.000498\n",
      "Minibatch CKA (unbiased HSIC): 0.000162\n",
      "Difference: 0.000660\n",
      "\n",
      "=== Convergence Test ===\n",
      "Batch size | N batches | Minibatch CKA | Difference from exact\n",
      "-----------------------------------------------------------------\n",
      "        10 |        10 |      0.026911 | 0.027409\n",
      "        10 |        20 |     -0.048918 | 0.048420\n",
      "        10 |        50 |      0.024392 | 0.024890\n",
      "        10 |       100 |     -0.001390 | 0.000891\n",
      "        25 |        10 |     -0.019966 | 0.019467\n",
      "        25 |        20 |     -0.015000 | 0.014501\n",
      "        25 |        50 |      0.018446 | 0.018945\n",
      "        25 |       100 |      0.002189 | 0.002687\n",
      "        50 |        10 |      0.007660 | 0.008159\n",
      "        50 |        20 |     -0.006197 | 0.005699\n",
      "        50 |        50 |     -0.001846 | 0.001348\n",
      "        50 |       100 |      0.002714 | 0.003212\n",
      "       100 |        10 |     -0.003623 | 0.003124\n",
      "       100 |        20 |      0.002183 | 0.002681\n",
      "       100 |        50 |     -0.004052 | 0.003553\n",
      "       100 |       100 |     -0.000196 | 0.000302\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_kernels\n",
    "\n",
    "def center_gram(K):\n",
    "    \"\"\"Center a Gram matrix.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    return H @ K @ H\n",
    "\n",
    "def hsic_biased(K, L):\n",
    "    \"\"\"Hilbert-Schmidt Independence Criterion (biased estimator).\"\"\"\n",
    "    n = K.shape[0]\n",
    "    Kc, Lc = center_gram(K), center_gram(L)\n",
    "    return np.trace(Kc @ Lc) / (n - 1) ** 2\n",
    "\n",
    "def hsic_unbiased(K, L):\n",
    "    \"\"\"Unbiased HSIC estimator (Song et al. 2007).\"\"\"\n",
    "    n = K.shape[0]\n",
    "    if n < 4:\n",
    "        raise ValueError(\"Need at least 4 samples for unbiased HSIC\")\n",
    "\n",
    "    # Zero out diagonals\n",
    "    K_tilde = K.copy()\n",
    "    L_tilde = L.copy()\n",
    "    np.fill_diagonal(K_tilde, 0)\n",
    "    np.fill_diagonal(L_tilde, 0)\n",
    "\n",
    "    ones = np.ones(n)\n",
    "    \n",
    "    term1 = np.trace(K_tilde @ L_tilde)\n",
    "    term2 = (ones.T @ K_tilde @ ones) * (ones.T @ L_tilde @ ones) / ((n - 1) * (n - 2))\n",
    "    term3 = 2 * (ones.T @ K_tilde @ L_tilde @ ones) / (n - 2)\n",
    "    \n",
    "    return (term1 + term2 - term3) / (n * (n - 3))\n",
    "\n",
    "def cka_exact(X, Y, kernel=\"linear\", use_unbiased=False, **kwargs):\n",
    "    \"\"\"\n",
    "    Compute exact CKA between two representations.\n",
    "    \"\"\"\n",
    "    if kernel == \"linear\":\n",
    "        K = X @ X.T\n",
    "        L = Y @ Y.T\n",
    "    else:\n",
    "        K = pairwise_kernels(X, metric=kernel, **kwargs)\n",
    "        L = pairwise_kernels(Y, metric=kernel, **kwargs)\n",
    "    \n",
    "    # Choose HSIC estimator\n",
    "    hsic_func = hsic_unbiased if use_unbiased else hsic_biased\n",
    "    \n",
    "    hsic_xy = hsic_func(K, L)\n",
    "    hsic_xx = hsic_func(K, K)\n",
    "    hsic_yy = hsic_func(L, L)\n",
    "    \n",
    "    return hsic_xy / np.sqrt(hsic_xx * hsic_yy + 1e-12)\n",
    "\n",
    "def cka_minibatch_approximation(X, Y, batch_size=50, n_batches=20, kernel=\"linear\", \n",
    "                              use_unbiased=True, **kwargs):\n",
    "    \"\"\"\n",
    "    Minibatch approximation of CKA using proper sampling without replacement.\n",
    "    \"\"\"\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    # Choose HSIC estimator\n",
    "    hsic_func = hsic_unbiased if use_unbiased else hsic_biased\n",
    "    \n",
    "    hsic_xy_sum = 0\n",
    "    hsic_xx_sum = 0  \n",
    "    hsic_yy_sum = 0\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        # Sample without replacement for this minibatch\n",
    "        indices = np.random.choice(n_samples, size=batch_size, replace=False)\n",
    "        X_batch = X[indices]\n",
    "        Y_batch = Y[indices]\n",
    "        \n",
    "        # Compute gram matrices for this batch\n",
    "        if kernel == \"linear\":\n",
    "            K_batch = X_batch @ X_batch.T\n",
    "            L_batch = Y_batch @ Y_batch.T\n",
    "        else:\n",
    "            K_batch = pairwise_kernels(X_batch, metric=kernel, **kwargs)\n",
    "            L_batch = pairwise_kernels(Y_batch, metric=kernel, **kwargs)\n",
    "        \n",
    "        # Accumulate HSIC estimates\n",
    "        hsic_xy_sum += hsic_func(K_batch, L_batch)\n",
    "        hsic_xx_sum += hsic_func(K_batch, K_batch)\n",
    "        hsic_yy_sum += hsic_func(L_batch, L_batch)\n",
    "    \n",
    "    # Average and compute CKA\n",
    "    hsic_xy_avg = hsic_xy_sum / n_batches\n",
    "    hsic_xx_avg = hsic_xx_sum / n_batches\n",
    "    hsic_yy_avg = hsic_yy_sum / n_batches\n",
    "    \n",
    "    return hsic_xy_avg / np.sqrt(hsic_xx_avg * hsic_yy_avg + 1e-12)\n",
    "\n",
    "# Test the implementation\n",
    "np.random.seed(42)  # For reproducibility\n",
    "X = np.random.randn(1000, 128)  # Larger dataset\n",
    "Y = np.random.randn(1000, 256)\n",
    "\n",
    "print(\"=== Comparison with BIASED HSIC ===\")\n",
    "# Exact CKA with biased HSIC\n",
    "exact_cka_biased = cka_exact(X, Y, kernel=\"linear\", use_unbiased=False)\n",
    "print(f\"Exact CKA (biased HSIC): {exact_cka_biased:.6f}\")\n",
    "\n",
    "# Minibatch approximation with biased HSIC  \n",
    "minibatch_cka_biased = cka_minibatch_approximation(X, Y, batch_size=100, n_batches=50, \n",
    "                                                 kernel=\"linear\", use_unbiased=False)\n",
    "print(f\"Minibatch CKA (biased HSIC): {minibatch_cka_biased:.6f}\")\n",
    "print(f\"Difference: {abs(exact_cka_biased - minibatch_cka_biased):.6f}\")\n",
    "\n",
    "print(\"\\n=== Comparison with UNBIASED HSIC ===\")\n",
    "# Exact CKA with unbiased HSIC\n",
    "exact_cka_unbiased = cka_exact(X, Y, kernel=\"linear\", use_unbiased=True)\n",
    "print(f\"Exact CKA (unbiased HSIC): {exact_cka_unbiased:.6f}\")\n",
    "\n",
    "# Minibatch approximation with unbiased HSIC\n",
    "minibatch_cka_unbiased = cka_minibatch_approximation(X, Y, batch_size=100, n_batches=50,\n",
    "                                                   kernel=\"linear\", use_unbiased=True)\n",
    "print(f\"Minibatch CKA (unbiased HSIC): {minibatch_cka_unbiased:.6f}\")\n",
    "print(f\"Difference: {abs(exact_cka_unbiased - minibatch_cka_unbiased):.6f}\")\n",
    "\n",
    "print(\"\\n=== Convergence Test ===\")\n",
    "# Test convergence with increasing number of batches\n",
    "batch_sizes = [10, 25, 50, 100]\n",
    "n_batches_list = [10, 20, 50, 100]\n",
    "\n",
    "print(\"Batch size | N batches | Minibatch CKA | Difference from exact\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    for n_batches in n_batches_list:\n",
    "        if batch_size * n_batches <= 10000:  # Reasonable computational limit\n",
    "            approx_cka = cka_minibatch_approximation(X, Y, batch_size=batch_size, \n",
    "                                                   n_batches=n_batches, kernel=\"linear\", \n",
    "                                                   use_unbiased=True)\n",
    "            diff = abs(exact_cka_unbiased - approx_cka)\n",
    "            print(f\"{batch_size:10d} | {n_batches:9d} | {approx_cka:13.6f} | {diff:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponce_env",
   "language": "python",
   "name": "ponce_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
