{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51980504-a26a-4b26-9155-e3f2e6dc4a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from torchvision import models\n",
    "from torchvision.models.feature_extraction import (\n",
    "            create_feature_extractor,\n",
    "                get_graph_node_names,\n",
    "                )\n",
    "sys.path.append(\"/Users/tizianocausin/Desktop/backUp20240609/summer2025/ponce_lab/exp_set/python_scripts/src\")\n",
    "from dim_redu_anns.utils import get_relevant_output_layers, get_layer_out_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59ae1be6-b457-4bb4-afbf-c0e8097fa932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv_proj', 'encoder.layers.encoder_layer_0.add_1', 'encoder.layers.encoder_layer_2.add_1', 'encoder.layers.encoder_layer_4.add_1', 'encoder.layers.encoder_layer_6.add_1', 'encoder.layers.encoder_layer_8.add_1', 'encoder.layers.encoder_layer_10.add_1', 'encoder.layers.encoder_layer_11.add_1', 'encoder.ln', 'heads.head']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_proj torch.Size([768, 14, 14])\n",
      "encoder.layers.encoder_layer_0.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_2.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_4.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_6.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_8.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_10.add_1 torch.Size([197, 768])\n",
      "encoder.layers.encoder_layer_11.add_1 torch.Size([197, 768])\n",
      "encoder.ln torch.Size([197, 768])\n",
      "heads.head torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "layers = get_relevant_output_layers(\"vit_b_16\")\n",
    "print(layers)\n",
    "model_name = \"vit_b_16\"\n",
    "model_cls = getattr(models, model_name)\n",
    "model = model_cls(pretrained=True).to(device).eval()\n",
    "for layer in layers:\n",
    "    feature_extractor = create_feature_extractor(\n",
    "    model, return_nodes=[layer]\n",
    "    ).to(device)\n",
    "    dims = get_layer_out_shape(feature_extractor, layer)\n",
    "    print(layer, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1eb352ca-c88e-4900-ac25-ea56f8a98831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n",
      "(['x', 'getattr', 'getitem', 'getitem_1', 'getitem_2', 'getitem_3', 'eq', '_assert', 'eq_1', '_assert_1', 'floordiv', 'floordiv_1', 'conv_proj', 'mul', 'reshape', 'permute', 'getattr_1', 'getitem_4', 'class_token', 'expand', 'cat', 'encoder.dim', 'encoder.eq', 'encoder.getattr', 'encoder._assert', 'encoder.encoder_pos_embedding', 'encoder.add', 'encoder.dropout', 'encoder.layers.encoder_layer_0.dim', 'encoder.layers.encoder_layer_0.eq', 'encoder.layers.encoder_layer_0.getattr', 'encoder.layers.encoder_layer_0._assert', 'encoder.layers.encoder_layer_0.ln', 'encoder.layers.encoder_layer_0.self_attention', 'encoder.layers.encoder_layer_0.getitem', 'encoder.layers.encoder_layer_0.getitem_1', 'encoder.layers.encoder_layer_0.dropout', 'encoder.layers.encoder_layer_0.add', 'encoder.layers.encoder_layer_0.ln_1', 'encoder.layers.encoder_layer_0.mlp', 'encoder.layers.encoder_layer_0.add_1', 'encoder.layers.encoder_layer_1.dim', 'encoder.layers.encoder_layer_1.eq', 'encoder.layers.encoder_layer_1.getattr', 'encoder.layers.encoder_layer_1._assert', 'encoder.layers.encoder_layer_1.ln', 'encoder.layers.encoder_layer_1.self_attention', 'encoder.layers.encoder_layer_1.getitem', 'encoder.layers.encoder_layer_1.getitem_1', 'encoder.layers.encoder_layer_1.dropout', 'encoder.layers.encoder_layer_1.add', 'encoder.layers.encoder_layer_1.ln_1', 'encoder.layers.encoder_layer_1.mlp', 'encoder.layers.encoder_layer_1.add_1', 'encoder.layers.encoder_layer_2.dim', 'encoder.layers.encoder_layer_2.eq', 'encoder.layers.encoder_layer_2.getattr', 'encoder.layers.encoder_layer_2._assert', 'encoder.layers.encoder_layer_2.ln', 'encoder.layers.encoder_layer_2.self_attention', 'encoder.layers.encoder_layer_2.getitem', 'encoder.layers.encoder_layer_2.getitem_1', 'encoder.layers.encoder_layer_2.dropout', 'encoder.layers.encoder_layer_2.add', 'encoder.layers.encoder_layer_2.ln_1', 'encoder.layers.encoder_layer_2.mlp', 'encoder.layers.encoder_layer_2.add_1', 'encoder.layers.encoder_layer_3.dim', 'encoder.layers.encoder_layer_3.eq', 'encoder.layers.encoder_layer_3.getattr', 'encoder.layers.encoder_layer_3._assert', 'encoder.layers.encoder_layer_3.ln', 'encoder.layers.encoder_layer_3.self_attention', 'encoder.layers.encoder_layer_3.getitem', 'encoder.layers.encoder_layer_3.getitem_1', 'encoder.layers.encoder_layer_3.dropout', 'encoder.layers.encoder_layer_3.add', 'encoder.layers.encoder_layer_3.ln_1', 'encoder.layers.encoder_layer_3.mlp', 'encoder.layers.encoder_layer_3.add_1', 'encoder.layers.encoder_layer_4.dim', 'encoder.layers.encoder_layer_4.eq', 'encoder.layers.encoder_layer_4.getattr', 'encoder.layers.encoder_layer_4._assert', 'encoder.layers.encoder_layer_4.ln', 'encoder.layers.encoder_layer_4.self_attention', 'encoder.layers.encoder_layer_4.getitem', 'encoder.layers.encoder_layer_4.getitem_1', 'encoder.layers.encoder_layer_4.dropout', 'encoder.layers.encoder_layer_4.add', 'encoder.layers.encoder_layer_4.ln_1', 'encoder.layers.encoder_layer_4.mlp', 'encoder.layers.encoder_layer_4.add_1', 'encoder.layers.encoder_layer_5.dim', 'encoder.layers.encoder_layer_5.eq', 'encoder.layers.encoder_layer_5.getattr', 'encoder.layers.encoder_layer_5._assert', 'encoder.layers.encoder_layer_5.ln', 'encoder.layers.encoder_layer_5.self_attention', 'encoder.layers.encoder_layer_5.getitem', 'encoder.layers.encoder_layer_5.getitem_1', 'encoder.layers.encoder_layer_5.dropout', 'encoder.layers.encoder_layer_5.add', 'encoder.layers.encoder_layer_5.ln_1', 'encoder.layers.encoder_layer_5.mlp', 'encoder.layers.encoder_layer_5.add_1', 'encoder.layers.encoder_layer_6.dim', 'encoder.layers.encoder_layer_6.eq', 'encoder.layers.encoder_layer_6.getattr', 'encoder.layers.encoder_layer_6._assert', 'encoder.layers.encoder_layer_6.ln', 'encoder.layers.encoder_layer_6.self_attention', 'encoder.layers.encoder_layer_6.getitem', 'encoder.layers.encoder_layer_6.getitem_1', 'encoder.layers.encoder_layer_6.dropout', 'encoder.layers.encoder_layer_6.add', 'encoder.layers.encoder_layer_6.ln_1', 'encoder.layers.encoder_layer_6.mlp', 'encoder.layers.encoder_layer_6.add_1', 'encoder.layers.encoder_layer_7.dim', 'encoder.layers.encoder_layer_7.eq', 'encoder.layers.encoder_layer_7.getattr', 'encoder.layers.encoder_layer_7._assert', 'encoder.layers.encoder_layer_7.ln', 'encoder.layers.encoder_layer_7.self_attention', 'encoder.layers.encoder_layer_7.getitem', 'encoder.layers.encoder_layer_7.getitem_1', 'encoder.layers.encoder_layer_7.dropout', 'encoder.layers.encoder_layer_7.add', 'encoder.layers.encoder_layer_7.ln_1', 'encoder.layers.encoder_layer_7.mlp', 'encoder.layers.encoder_layer_7.add_1', 'encoder.layers.encoder_layer_8.dim', 'encoder.layers.encoder_layer_8.eq', 'encoder.layers.encoder_layer_8.getattr', 'encoder.layers.encoder_layer_8._assert', 'encoder.layers.encoder_layer_8.ln', 'encoder.layers.encoder_layer_8.self_attention', 'encoder.layers.encoder_layer_8.getitem', 'encoder.layers.encoder_layer_8.getitem_1', 'encoder.layers.encoder_layer_8.dropout', 'encoder.layers.encoder_layer_8.add', 'encoder.layers.encoder_layer_8.ln_1', 'encoder.layers.encoder_layer_8.mlp', 'encoder.layers.encoder_layer_8.add_1', 'encoder.layers.encoder_layer_9.dim', 'encoder.layers.encoder_layer_9.eq', 'encoder.layers.encoder_layer_9.getattr', 'encoder.layers.encoder_layer_9._assert', 'encoder.layers.encoder_layer_9.ln', 'encoder.layers.encoder_layer_9.self_attention', 'encoder.layers.encoder_layer_9.getitem', 'encoder.layers.encoder_layer_9.getitem_1', 'encoder.layers.encoder_layer_9.dropout', 'encoder.layers.encoder_layer_9.add', 'encoder.layers.encoder_layer_9.ln_1', 'encoder.layers.encoder_layer_9.mlp', 'encoder.layers.encoder_layer_9.add_1', 'encoder.layers.encoder_layer_10.dim', 'encoder.layers.encoder_layer_10.eq', 'encoder.layers.encoder_layer_10.getattr', 'encoder.layers.encoder_layer_10._assert', 'encoder.layers.encoder_layer_10.ln', 'encoder.layers.encoder_layer_10.self_attention', 'encoder.layers.encoder_layer_10.getitem', 'encoder.layers.encoder_layer_10.getitem_1', 'encoder.layers.encoder_layer_10.dropout', 'encoder.layers.encoder_layer_10.add', 'encoder.layers.encoder_layer_10.ln_1', 'encoder.layers.encoder_layer_10.mlp', 'encoder.layers.encoder_layer_10.add_1', 'encoder.layers.encoder_layer_11.dim', 'encoder.layers.encoder_layer_11.eq', 'encoder.layers.encoder_layer_11.getattr', 'encoder.layers.encoder_layer_11._assert', 'encoder.layers.encoder_layer_11.ln', 'encoder.layers.encoder_layer_11.self_attention', 'encoder.layers.encoder_layer_11.getitem', 'encoder.layers.encoder_layer_11.getitem_1', 'encoder.layers.encoder_layer_11.dropout', 'encoder.layers.encoder_layer_11.add', 'encoder.layers.encoder_layer_11.ln_1', 'encoder.layers.encoder_layer_11.mlp', 'encoder.layers.encoder_layer_11.add_1', 'encoder.ln', 'getitem_5', 'heads.head'], ['x', 'getattr', 'getitem', 'getitem_1', 'getitem_2', 'getitem_3', 'eq', '_assert', 'eq_1', '_assert_1', 'floordiv', 'floordiv_1', 'conv_proj', 'mul', 'reshape', 'permute', 'getattr_1', 'getitem_4', 'class_token', 'expand', 'cat', 'encoder.dim', 'encoder.eq', 'encoder.getattr', 'encoder._assert', 'encoder.encoder_pos_embedding', 'encoder.add', 'encoder.dropout', 'encoder.layers.encoder_layer_0.dim', 'encoder.layers.encoder_layer_0.eq', 'encoder.layers.encoder_layer_0.getattr', 'encoder.layers.encoder_layer_0._assert', 'encoder.layers.encoder_layer_0.ln', 'encoder.layers.encoder_layer_0.self_attention', 'encoder.layers.encoder_layer_0.getitem', 'encoder.layers.encoder_layer_0.getitem_1', 'encoder.layers.encoder_layer_0.dropout', 'encoder.layers.encoder_layer_0.add', 'encoder.layers.encoder_layer_0.ln_1', 'encoder.layers.encoder_layer_0.mlp', 'encoder.layers.encoder_layer_0.add_1', 'encoder.layers.encoder_layer_1.dim', 'encoder.layers.encoder_layer_1.eq', 'encoder.layers.encoder_layer_1.getattr', 'encoder.layers.encoder_layer_1._assert', 'encoder.layers.encoder_layer_1.ln', 'encoder.layers.encoder_layer_1.self_attention', 'encoder.layers.encoder_layer_1.getitem', 'encoder.layers.encoder_layer_1.getitem_1', 'encoder.layers.encoder_layer_1.dropout', 'encoder.layers.encoder_layer_1.add', 'encoder.layers.encoder_layer_1.ln_1', 'encoder.layers.encoder_layer_1.mlp', 'encoder.layers.encoder_layer_1.add_1', 'encoder.layers.encoder_layer_2.dim', 'encoder.layers.encoder_layer_2.eq', 'encoder.layers.encoder_layer_2.getattr', 'encoder.layers.encoder_layer_2._assert', 'encoder.layers.encoder_layer_2.ln', 'encoder.layers.encoder_layer_2.self_attention', 'encoder.layers.encoder_layer_2.getitem', 'encoder.layers.encoder_layer_2.getitem_1', 'encoder.layers.encoder_layer_2.dropout', 'encoder.layers.encoder_layer_2.add', 'encoder.layers.encoder_layer_2.ln_1', 'encoder.layers.encoder_layer_2.mlp', 'encoder.layers.encoder_layer_2.add_1', 'encoder.layers.encoder_layer_3.dim', 'encoder.layers.encoder_layer_3.eq', 'encoder.layers.encoder_layer_3.getattr', 'encoder.layers.encoder_layer_3._assert', 'encoder.layers.encoder_layer_3.ln', 'encoder.layers.encoder_layer_3.self_attention', 'encoder.layers.encoder_layer_3.getitem', 'encoder.layers.encoder_layer_3.getitem_1', 'encoder.layers.encoder_layer_3.dropout', 'encoder.layers.encoder_layer_3.add', 'encoder.layers.encoder_layer_3.ln_1', 'encoder.layers.encoder_layer_3.mlp', 'encoder.layers.encoder_layer_3.add_1', 'encoder.layers.encoder_layer_4.dim', 'encoder.layers.encoder_layer_4.eq', 'encoder.layers.encoder_layer_4.getattr', 'encoder.layers.encoder_layer_4._assert', 'encoder.layers.encoder_layer_4.ln', 'encoder.layers.encoder_layer_4.self_attention', 'encoder.layers.encoder_layer_4.getitem', 'encoder.layers.encoder_layer_4.getitem_1', 'encoder.layers.encoder_layer_4.dropout', 'encoder.layers.encoder_layer_4.add', 'encoder.layers.encoder_layer_4.ln_1', 'encoder.layers.encoder_layer_4.mlp', 'encoder.layers.encoder_layer_4.add_1', 'encoder.layers.encoder_layer_5.dim', 'encoder.layers.encoder_layer_5.eq', 'encoder.layers.encoder_layer_5.getattr', 'encoder.layers.encoder_layer_5._assert', 'encoder.layers.encoder_layer_5.ln', 'encoder.layers.encoder_layer_5.self_attention', 'encoder.layers.encoder_layer_5.getitem', 'encoder.layers.encoder_layer_5.getitem_1', 'encoder.layers.encoder_layer_5.dropout', 'encoder.layers.encoder_layer_5.add', 'encoder.layers.encoder_layer_5.ln_1', 'encoder.layers.encoder_layer_5.mlp', 'encoder.layers.encoder_layer_5.add_1', 'encoder.layers.encoder_layer_6.dim', 'encoder.layers.encoder_layer_6.eq', 'encoder.layers.encoder_layer_6.getattr', 'encoder.layers.encoder_layer_6._assert', 'encoder.layers.encoder_layer_6.ln', 'encoder.layers.encoder_layer_6.self_attention', 'encoder.layers.encoder_layer_6.getitem', 'encoder.layers.encoder_layer_6.getitem_1', 'encoder.layers.encoder_layer_6.dropout', 'encoder.layers.encoder_layer_6.add', 'encoder.layers.encoder_layer_6.ln_1', 'encoder.layers.encoder_layer_6.mlp', 'encoder.layers.encoder_layer_6.add_1', 'encoder.layers.encoder_layer_7.dim', 'encoder.layers.encoder_layer_7.eq', 'encoder.layers.encoder_layer_7.getattr', 'encoder.layers.encoder_layer_7._assert', 'encoder.layers.encoder_layer_7.ln', 'encoder.layers.encoder_layer_7.self_attention', 'encoder.layers.encoder_layer_7.getitem', 'encoder.layers.encoder_layer_7.getitem_1', 'encoder.layers.encoder_layer_7.dropout', 'encoder.layers.encoder_layer_7.add', 'encoder.layers.encoder_layer_7.ln_1', 'encoder.layers.encoder_layer_7.mlp', 'encoder.layers.encoder_layer_7.add_1', 'encoder.layers.encoder_layer_8.dim', 'encoder.layers.encoder_layer_8.eq', 'encoder.layers.encoder_layer_8.getattr', 'encoder.layers.encoder_layer_8._assert', 'encoder.layers.encoder_layer_8.ln', 'encoder.layers.encoder_layer_8.self_attention', 'encoder.layers.encoder_layer_8.getitem', 'encoder.layers.encoder_layer_8.getitem_1', 'encoder.layers.encoder_layer_8.dropout', 'encoder.layers.encoder_layer_8.add', 'encoder.layers.encoder_layer_8.ln_1', 'encoder.layers.encoder_layer_8.mlp', 'encoder.layers.encoder_layer_8.add_1', 'encoder.layers.encoder_layer_9.dim', 'encoder.layers.encoder_layer_9.eq', 'encoder.layers.encoder_layer_9.getattr', 'encoder.layers.encoder_layer_9._assert', 'encoder.layers.encoder_layer_9.ln', 'encoder.layers.encoder_layer_9.self_attention', 'encoder.layers.encoder_layer_9.getitem', 'encoder.layers.encoder_layer_9.getitem_1', 'encoder.layers.encoder_layer_9.dropout', 'encoder.layers.encoder_layer_9.add', 'encoder.layers.encoder_layer_9.ln_1', 'encoder.layers.encoder_layer_9.mlp', 'encoder.layers.encoder_layer_9.add_1', 'encoder.layers.encoder_layer_10.dim', 'encoder.layers.encoder_layer_10.eq', 'encoder.layers.encoder_layer_10.getattr', 'encoder.layers.encoder_layer_10._assert', 'encoder.layers.encoder_layer_10.ln', 'encoder.layers.encoder_layer_10.self_attention', 'encoder.layers.encoder_layer_10.getitem', 'encoder.layers.encoder_layer_10.getitem_1', 'encoder.layers.encoder_layer_10.dropout', 'encoder.layers.encoder_layer_10.add', 'encoder.layers.encoder_layer_10.ln_1', 'encoder.layers.encoder_layer_10.mlp', 'encoder.layers.encoder_layer_10.add_1', 'encoder.layers.encoder_layer_11.dim', 'encoder.layers.encoder_layer_11.eq', 'encoder.layers.encoder_layer_11.getattr', 'encoder.layers.encoder_layer_11._assert', 'encoder.layers.encoder_layer_11.ln', 'encoder.layers.encoder_layer_11.self_attention', 'encoder.layers.encoder_layer_11.getitem', 'encoder.layers.encoder_layer_11.getitem_1', 'encoder.layers.encoder_layer_11.dropout', 'encoder.layers.encoder_layer_11.add', 'encoder.layers.encoder_layer_11.ln_1', 'encoder.layers.encoder_layer_11.mlp', 'encoder.layers.encoder_layer_11.add_1', 'encoder.ln', 'getitem_5', 'heads.head'])\n"
     ]
    }
   ],
   "source": [
    "print(model)\n",
    "print(get_graph_node_names(model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91931262-b8b2-4701-bba7-dfc8b3c1f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.relu_1', 'layer1.0.conv3', 'layer1.0.bn3', 'layer1.0.downsample.0', 'layer1.0.downsample.1', 'layer1.0.add', 'layer1.0.relu_2', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.relu_1', 'layer1.1.conv3', 'layer1.1.bn3', 'layer1.1.add', 'layer1.1.relu_2', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.relu_1', 'layer1.2.conv3', 'layer1.2.bn3', 'layer1.2.add', 'layer1.2.relu_2', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.relu_1', 'layer2.0.conv3', 'layer2.0.bn3', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_2', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.relu_1', 'layer2.1.conv3', 'layer2.1.bn3', 'layer2.1.add', 'layer2.1.relu_2', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.relu_1', 'layer2.2.conv3', 'layer2.2.bn3', 'layer2.2.add', 'layer2.2.relu_2', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.relu_1', 'layer2.3.conv3', 'layer2.3.bn3', 'layer2.3.add', 'layer2.3.relu_2', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.relu_1', 'layer3.0.conv3', 'layer3.0.bn3', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_2', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.relu_1', 'layer3.1.conv3', 'layer3.1.bn3', 'layer3.1.add', 'layer3.1.relu_2', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.relu_1', 'layer3.2.conv3', 'layer3.2.bn3', 'layer3.2.add', 'layer3.2.relu_2', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.relu_1', 'layer3.3.conv3', 'layer3.3.bn3', 'layer3.3.add', 'layer3.3.relu_2', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.relu_1', 'layer3.4.conv3', 'layer3.4.bn3', 'layer3.4.add', 'layer3.4.relu_2', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.relu_1', 'layer3.5.conv3', 'layer3.5.bn3', 'layer3.5.add', 'layer3.5.relu_2', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.relu_1', 'layer4.0.conv3', 'layer4.0.bn3', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_2', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.relu_1', 'layer4.1.conv3', 'layer4.1.bn3', 'layer4.1.add', 'layer4.1.relu_2', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.relu_1', 'layer4.2.conv3', 'layer4.2.bn3', 'layer4.2.add', 'layer4.2.relu_2', 'avgpool', 'flatten', 'fc'], ['x', 'conv1', 'bn1', 'relu', 'maxpool', 'layer1.0.conv1', 'layer1.0.bn1', 'layer1.0.relu', 'layer1.0.conv2', 'layer1.0.bn2', 'layer1.0.relu_1', 'layer1.0.conv3', 'layer1.0.bn3', 'layer1.0.downsample.0', 'layer1.0.downsample.1', 'layer1.0.add', 'layer1.0.relu_2', 'layer1.1.conv1', 'layer1.1.bn1', 'layer1.1.relu', 'layer1.1.conv2', 'layer1.1.bn2', 'layer1.1.relu_1', 'layer1.1.conv3', 'layer1.1.bn3', 'layer1.1.add', 'layer1.1.relu_2', 'layer1.2.conv1', 'layer1.2.bn1', 'layer1.2.relu', 'layer1.2.conv2', 'layer1.2.bn2', 'layer1.2.relu_1', 'layer1.2.conv3', 'layer1.2.bn3', 'layer1.2.add', 'layer1.2.relu_2', 'layer2.0.conv1', 'layer2.0.bn1', 'layer2.0.relu', 'layer2.0.conv2', 'layer2.0.bn2', 'layer2.0.relu_1', 'layer2.0.conv3', 'layer2.0.bn3', 'layer2.0.downsample.0', 'layer2.0.downsample.1', 'layer2.0.add', 'layer2.0.relu_2', 'layer2.1.conv1', 'layer2.1.bn1', 'layer2.1.relu', 'layer2.1.conv2', 'layer2.1.bn2', 'layer2.1.relu_1', 'layer2.1.conv3', 'layer2.1.bn3', 'layer2.1.add', 'layer2.1.relu_2', 'layer2.2.conv1', 'layer2.2.bn1', 'layer2.2.relu', 'layer2.2.conv2', 'layer2.2.bn2', 'layer2.2.relu_1', 'layer2.2.conv3', 'layer2.2.bn3', 'layer2.2.add', 'layer2.2.relu_2', 'layer2.3.conv1', 'layer2.3.bn1', 'layer2.3.relu', 'layer2.3.conv2', 'layer2.3.bn2', 'layer2.3.relu_1', 'layer2.3.conv3', 'layer2.3.bn3', 'layer2.3.add', 'layer2.3.relu_2', 'layer3.0.conv1', 'layer3.0.bn1', 'layer3.0.relu', 'layer3.0.conv2', 'layer3.0.bn2', 'layer3.0.relu_1', 'layer3.0.conv3', 'layer3.0.bn3', 'layer3.0.downsample.0', 'layer3.0.downsample.1', 'layer3.0.add', 'layer3.0.relu_2', 'layer3.1.conv1', 'layer3.1.bn1', 'layer3.1.relu', 'layer3.1.conv2', 'layer3.1.bn2', 'layer3.1.relu_1', 'layer3.1.conv3', 'layer3.1.bn3', 'layer3.1.add', 'layer3.1.relu_2', 'layer3.2.conv1', 'layer3.2.bn1', 'layer3.2.relu', 'layer3.2.conv2', 'layer3.2.bn2', 'layer3.2.relu_1', 'layer3.2.conv3', 'layer3.2.bn3', 'layer3.2.add', 'layer3.2.relu_2', 'layer3.3.conv1', 'layer3.3.bn1', 'layer3.3.relu', 'layer3.3.conv2', 'layer3.3.bn2', 'layer3.3.relu_1', 'layer3.3.conv3', 'layer3.3.bn3', 'layer3.3.add', 'layer3.3.relu_2', 'layer3.4.conv1', 'layer3.4.bn1', 'layer3.4.relu', 'layer3.4.conv2', 'layer3.4.bn2', 'layer3.4.relu_1', 'layer3.4.conv3', 'layer3.4.bn3', 'layer3.4.add', 'layer3.4.relu_2', 'layer3.5.conv1', 'layer3.5.bn1', 'layer3.5.relu', 'layer3.5.conv2', 'layer3.5.bn2', 'layer3.5.relu_1', 'layer3.5.conv3', 'layer3.5.bn3', 'layer3.5.add', 'layer3.5.relu_2', 'layer4.0.conv1', 'layer4.0.bn1', 'layer4.0.relu', 'layer4.0.conv2', 'layer4.0.bn2', 'layer4.0.relu_1', 'layer4.0.conv3', 'layer4.0.bn3', 'layer4.0.downsample.0', 'layer4.0.downsample.1', 'layer4.0.add', 'layer4.0.relu_2', 'layer4.1.conv1', 'layer4.1.bn1', 'layer4.1.relu', 'layer4.1.conv2', 'layer4.1.bn2', 'layer4.1.relu_1', 'layer4.1.conv3', 'layer4.1.bn3', 'layer4.1.add', 'layer4.1.relu_2', 'layer4.2.conv1', 'layer4.2.bn1', 'layer4.2.relu', 'layer4.2.conv2', 'layer4.2.bn2', 'layer4.2.relu_1', 'layer4.2.conv3', 'layer4.2.bn3', 'layer4.2.add', 'layer4.2.relu_2', 'avgpool', 'flatten', 'fc'])\n"
     ]
    }
   ],
   "source": [
    "print(get_graph_node_names(model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce3ba1c9-713c-4813-862e-728bd4a9ea68",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m feature_extractor = \u001b[43mcreate_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mflatten\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m.to(device)\n\u001b[32m      4\u001b[39m get_layer_out_shape(model2, \u001b[33m\"\u001b[39m\u001b[33mflatten\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:510\u001b[39m, in \u001b[36mcreate_feature_extractor\u001b[39m\u001b[34m(model, return_nodes, train_return_nodes, eval_return_nodes, tracer_kwargs, suppress_diff_warning, concrete_args)\u001b[39m\n\u001b[32m    507\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mstr\u001b[39m(k): \u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m n.items()}\n\u001b[32m    509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_return_nodes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m510\u001b[39m     return_nodes = \u001b[43mto_strdict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    511\u001b[39m     train_return_nodes = deepcopy(return_nodes)\n\u001b[32m    512\u001b[39m     eval_return_nodes = deepcopy(return_nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:507\u001b[39m, in \u001b[36mcreate_feature_extractor.<locals>.to_strdict\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m    505\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(n, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m    506\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mstr\u001b[39m(i): \u001b[38;5;28mstr\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m n}\n\u001b[32m--> \u001b[39m\u001b[32m507\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;28mstr\u001b[39m(k): \u001b[38;5;28mstr\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m()}\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "feature_extractor = create_feature_extractor(\n",
    "model, return_nodes=\"flatten\"\n",
    ").to(device)\n",
    "get_layer_out_shape(model2, \"flatten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8df8813b-ad6a-44bb-aed5-c20ec12113f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1', 'layer1.0.relu_2', 'layer1.1.relu_2', 'layer1.2.relu_2', 'layer2.0.relu_2', 'layer2.1.relu_2', 'layer2.2.relu_2', 'layer2.3.relu_2', 'layer3.0.relu_2', 'layer3.1.relu_2', 'layer3.2.relu_2', 'layer3.3.relu_2', 'layer3.4.relu_2', 'layer3.5.relu_2', 'layer4.0.relu_2', 'layer4.1.relu_2', 'layer4.2.relu_2', 'avgpool']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/tizianocausin/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "node: 'conv1' is not present in model. Hint: use `get_graph_node_names` to make sure the `return_nodes` you specified are present. It may even be that you need to specify `train_return_nodes` and `eval_return_nodes` separately.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m model2 = model_cls(pretrained=\u001b[38;5;28;01mTrue\u001b[39;00m).to(device).eval()\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     feature_extractor = \u001b[43mcreate_feature_extractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_nodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m     12\u001b[39m     dims = get_layer_out_shape(feature_extractor, layer)\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(layer, dims)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/virtual_envs/ponce_env/lib/python3.12/site-packages/torchvision/models/feature_extraction.py:545\u001b[39m, in \u001b[36mcreate_feature_extractor\u001b[39m\u001b[34m(model, return_nodes, train_return_nodes, eval_return_nodes, tracer_kwargs, suppress_diff_warning, concrete_args)\u001b[39m\n\u001b[32m    541\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m mode_return_nodes[mode].keys():\n\u001b[32m    542\u001b[39m     \u001b[38;5;66;03m# To check if a query is available we need to check that at least\u001b[39;00m\n\u001b[32m    543\u001b[39m     \u001b[38;5;66;03m# one of the available names starts with it up to a .\u001b[39;00m\n\u001b[32m    544\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m([re.match(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m(\u001b[39m\u001b[33m\\\u001b[39m\u001b[33m.|$)\u001b[39m\u001b[33m\"\u001b[39m, n) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m available_nodes]):\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    546\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnode: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m is not present in model. Hint: use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    547\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`get_graph_node_names` to make sure the \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    548\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`return_nodes` you specified are present. It may even \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    549\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mbe that you need to specify `train_return_nodes` and \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    550\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m`eval_return_nodes` separately.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    551\u001b[39m         )\n\u001b[32m    553\u001b[39m \u001b[38;5;66;03m# Remove existing output nodes (train mode)\u001b[39;00m\n\u001b[32m    554\u001b[39m orig_output_nodes = []\n",
      "\u001b[31mValueError\u001b[39m: node: 'conv1' is not present in model. Hint: use `get_graph_node_names` to make sure the `return_nodes` you specified are present. It may even be that you need to specify `train_return_nodes` and `eval_return_nodes` separately."
     ]
    }
   ],
   "source": [
    "device = \"cpu\"\n",
    "layers = get_relevant_output_layers(\"resnet50\")\n",
    "print(layers)\n",
    "model_name = \"resnet50\"\n",
    "model_cls = getattr(models, model_name)\n",
    "model2 = model_cls(pretrained=True).to(device).eval()\n",
    "\n",
    "for layer in layers:\n",
    "    feature_extractor = create_feature_extractor(\n",
    "    model, return_nodes=[layer]\n",
    "    ).to(device)\n",
    "    dims = get_layer_out_shape(feature_extractor, layer)\n",
    "    print(layer, dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61bed530-60c3-40bc-8dfa-2e41fd57a818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.max(np.zeros((197, 768)), axis=0).size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66cf0f-c130-4fbd-962c-141afad7371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ponce_env",
   "language": "python",
   "name": "ponce_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
